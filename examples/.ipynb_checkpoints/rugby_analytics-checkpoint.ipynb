{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Hierarchical model for Rugby prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Bayesian Rugby\n",
    "I came across the following blog post on http://danielweitzenfeld.github.io/passtheroc/blog/2014/10/28/bayes-premier-league/\n",
    "* Based on the work of [Baio and Blangiardo](www.statistica.it/gianluca/Research/BaioBlangiardo.pdf)\n",
    "In this example, we're going to reproduce the first model described in the paper using PyMC3.\n",
    "\n",
    "Since I am a rugby fan I decide to apply the results of the paper Bayesian Football to the Six Nations.\n",
    "Rugby is a physical sport popular worldwide.\n",
    "* Six Nations consists of Italy, Ireland, Scotland, England, France and Wales\n",
    "* Game consists of scoring tries (similar to touch downs) or kicking the goal.\n",
    "* Average player is something like 100kg and 1.82m tall.\n",
    "* Paul O'Connell the Irish captain is Height: 6' 6\" (1.98 m) Weight: 243 lbs (110 kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a data set only consisting of the Six Nations 2014 data, and use this to build a generative and explainable model about the Six Nations 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "Your estimate of the strength of a team depends on your estimates of the other strengths\n",
    "\n",
    "Ireland are a stronger team than Italy for example - but by how much?\n",
    "\n",
    "Source for Results 2014 are Wikipedia.\n",
    "I handcrafted these results\n",
    "Small data\n",
    "* We want to infer a latent parameter - that is the 'strength' of a team based only on their **scoring intensity**, and all we have are their scores and results, we can't accurately measure the 'strength' of a team. \n",
    "* Probabilistic Programming is a brilliant paradigm for modeling these **latent** parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 23 11:42:59 EDT 2015\r\n"
     ]
    }
   ],
   "source": [
    "!date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "try:\n",
    "    from StringIO import StringIO\n",
    "except ImportError:\n",
    "    from io import StringIO\n",
    "%matplotlib inline\n",
    "import pymc3 as pm, theano.tensor as tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is a Rugby prediction exercise. So we'll input some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_csv = StringIO(\"\"\"home_team,away_team,home_score,away_score\n",
    "Wales,Italy,23,15\n",
    "France,England,26,24\n",
    "Ireland,Scotland,28,6\n",
    "Ireland,Wales,26,3\n",
    "Scotland,England,0,20\n",
    "France,Italy,30,10\n",
    "Wales,France,27,6\n",
    "Italy,Scotland,20,21\n",
    "England,Ireland,13,10\n",
    "Ireland,Italy,46,7\n",
    "Scotland,France,17,19\n",
    "England,Wales,29,18\n",
    "Italy,England,11,52\n",
    "Wales,Scotland,51,3\n",
    "France,Ireland,20,22\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do we want to infer?\n",
    "* We want to infer the latent paremeters (every team's strength) that are generating the data we observe (the scorelines).\n",
    "* Moreover, we know that the scorelines are a noisy measurement of team strength, so ideally, we want a model that makes it easy to quantify our uncertainty about the underlying strengths.\n",
    "\n",
    "* Often we don't know what the Bayesian Model is explicitly, so we have to 'estimate' the Bayesian Model'\n",
    "* If we can't solve something, approximate it.\n",
    "\n",
    "* Markov-Chain Monte Carlo (MCMC) instead draws samples from the posterior.\n",
    "* Fortunately, this algorithm can be applied to almost any model.\n",
    "# What do we want?\n",
    "We want to quantify our uncertainty\n",
    "We want to also use this to generate a model\n",
    "We want the answers as distributions not point estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What assumptions do we know for our 'generative story'?\n",
    "* We know that the Six Nations in Rugby only has 6 teams - they each play each other once\n",
    "* We have data from last year!\n",
    "* We also know that in sports scoring is modelled as a Poisson distribution\n",
    "* We consider home advantage to be a strong effect in sports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model.\n",
    "\n",
    "<p>The league is made up by a total of T= 6 teams, playing each other once \n",
    "in a season. We indicate the number of points scored by the home and the away team in the g-th game of the season (15 games) as $y_{g1}$ and $y_{g2}$ respectively. </p>\n",
    "<p>The vector of observed counts $\\mathbb{y} = (y_{g1}, y_{g2})$ is modelled as independent Poisson:\n",
    "$y_{gi}| \\theta_{gj} \\tilde\\;\\;  Poisson(\\theta_{gj})$\n",
    "where the theta parameters represent the scoring intensity in the g-th game for the team playing at home (j=1) and away (j=2), respectively.</p>\n",
    "\n",
    "<p>We model these parameters according to a formulation that has been used widely in the statistical literature, assuming a log-linear random effect model:\n",
    "$$log \\theta_{g1} = home + att_{h(g)} + def_{a(g)} $$\n",
    "$$log \\theta_{g2} = att_{a(g)} + def_{h(g)}$$\n",
    "\n",
    "\n",
    "* The parameter home represents the advantage for the team hosting the game and we assume that this effect is constant for all the teams and throughout the season\n",
    "* The scoring intensity is determined jointly by the attack and defense ability of the two teams involved, represented by the parameters att and def, respectively\n",
    "\n",
    "* Conversely, for each t = 1, ..., T, the team-specific effects are modelled as exchangeable from a common distribution:\n",
    "\n",
    "* $att_{t}$ ~ $Normal(μ_att,τ_att)$ and $def_{t}$ ~Normal$(μ_{def},τ_{def})$\n",
    "\n",
    "Note that they're breaking out team strength into attacking and defending strength. A negative defense parameter will sap the mojo from the opposing team's attacking parameter.\n",
    "I made two tweaks to the model. It didn't make sense to me to have a μatt when we're enforcing the sum-to-zero constraint by subtracting the mean anyway. So I eliminated μatt and μdef\n",
    "Also because of the sum-to-zero constraint, it seemed to me that we needed an intercept term in the log-linear model, capturing the average goals scored per game by the away team. This we model with the following hyperprior.\n",
    "intercept~Normal(0,0.001)\n",
    "\n",
    "The hyper-priors on the attack and defense parameters are also flat\n",
    "* μatt~Normal(0,0.001)\n",
    "* μdef~Normal(0,0.001)\n",
    "* τatt~Γ(0.1,0.1)\n",
    "* τdef~Γ(0.1,0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_csv)\n",
    "\n",
    "teams = df.home_team.unique()\n",
    "teams = pd.DataFrame(teams, columns=['team'])\n",
    "teams['i'] = teams.index\n",
    "\n",
    "df = pd.merge(df, teams, left_on='home_team', right_on='team', how='left')\n",
    "df = df.rename(columns = {'i': 'i_home'}).drop('team', 1)\n",
    "df = pd.merge(df, teams, left_on='away_team', right_on='team', how='left')\n",
    "df = df.rename(columns = {'i': 'i_away'}).drop('team', 1)\n",
    "\n",
    "observed_home_goals = df.home_score.values\n",
    "observed_away_goals = df.away_score.values\n",
    "\n",
    "home_team = df.i_home.values\n",
    "away_team = df.i_away.values\n",
    "\n",
    "num_teams = len(df.i_home.drop_duplicates())\n",
    "num_games = len(home_team)\n",
    "\n",
    "g = df.groupby('i_away')\n",
    "att_starting_points = np.log(g.away_score.mean())\n",
    "g = df.groupby('i_home')\n",
    "def_starting_points = -np.log(g.away_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* We did some munging above and adjustments of the data to make it **tidier** for our model. \n",
    "* The log function to away scores and home scores is a standard trick in the sports analytics literature\n",
    "# Building of the model \n",
    "* We now build the model in PyMC3, specifying the global parameters, and the team-specific parameters and the likelihood function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pm.Model()\n",
    "with pm.Model() as model:\n",
    "    # global model parameters\n",
    "    home        = pm.Normal('home',      0, .0001)\n",
    "    tau_att     = pm.Gamma('tau_att',   .1, .1)\n",
    "    tau_def     = pm.Gamma('tau_def',   .1, .1)\n",
    "    intercept   = pm.Normal('intercept', 0, .0001)\n",
    "    \n",
    "    # team-specific model parameters\n",
    "    atts_star   = pm.Normal(\"atts_star\", \n",
    "                           mu   =0,\n",
    "                           tau  =tau_att, \n",
    "                           shape=num_teams)\n",
    "    defs_star   = pm.Normal(\"defs_star\", \n",
    "                           mu   =0,\n",
    "                           tau  =tau_def,  \n",
    "                           shape=num_teams) \n",
    " \n",
    "    atts        = pm.Deterministic('atts', atts_star - tt.mean(atts_star))\n",
    "    defs        = pm.Deterministic('defs', defs_star - tt.mean(defs_star))\n",
    "    home_theta  = tt.exp(intercept + home + atts[away_team] + defs[home_team])\n",
    "    away_theta  = tt.exp(intercept + atts[away_team] + defs[home_team])\n",
    "    \n",
    "    # likelihood of observed data\n",
    "    home_points = pm.Poisson('home_points', mu=home_theta, observed=observed_home_goals)\n",
    "    away_points = pm.Poisson('away_points', mu=away_theta, observed=observed_away_goals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We specified the model and the likelihood function\n",
    "\n",
    "* All this runs on a Theano graph under the hood\n",
    "* Now we need to fit our model using the Maximum A Posteriori algorithm to decide where to start out No U Turn Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/theano/scan_module/scan_perform_ext.py:133: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '87639' (I am process '87444')\n",
      "INFO:theano.gof.compilelock:Waiting for existing lock by process '87639' (I am process '87444')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/shidan/.theano/compiledir_Darwin-14.1.0-x86_64-i386-64bit-i386-2.7.6-64/lock_dir\n",
      "INFO:theano.gof.compilelock:To manually release the lock, delete /Users/shidan/.theano/compiledir_Darwin-14.1.0-x86_64-i386-64bit-i386-2.7.6-64/lock_dir\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [----             11%                  ] 235 of 2000 complete in 1.5 sec"
     ]
    }
   ],
   "source": [
    "with model:\n",
    "\n",
    "    start = pm.find_MAP()\n",
    "    step = pm.NUTS(state=start)\n",
    "    trace = pm.sample(2000, step, start=start, progressbar=True)\n",
    "\n",
    "    pm.traceplot(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Results\n",
    "From the above we can start to understand the different distributions of attacking strength and defensive strength.\n",
    "These are probabilistic estimates and help us better understand the uncertainty in sports analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
